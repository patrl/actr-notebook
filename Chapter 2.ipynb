{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Brasoveanu & Dotlaƒçil 2020: *Computational cognitive modeling and linguistic theory*\n",
    "\n",
    "## Patrick Elliott, 2020-06-04, *The linking lozenge*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you don't have a copy of the book yet, it's open access and available to download here: https://www.springer.com/gp/book/9783030318444\n",
    "\n",
    "Today I'll work up to the end of chapter 2. I'll tentatively plan to move onto chapter 3 in two weeks time.\n",
    "\n",
    "You don't really need to know any python to work through the examples, but the book is nevertheless pretty hands on. These slides are based on a runnable jupyter environment which you can find here: https://github.com/patrl/actr-notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why is this worth reading?\n",
    "\n",
    "How many *formally explicit* ways do we have of taking a competence theory, and integrating it into a plausible, and reasonably well-understood cognitive architecture, in a way that makes testable processing predictions?\n",
    "\n",
    "I'm a complete amateur when it comes to this domain, but my impressions:\n",
    "  - For syntactic theories, not very many at all.\n",
    "  - For semantic theories, perhaps none.\n",
    "  \n",
    "One upon a time this was considered to be a central goal of generative linguistics more broadly, but it seems to have fallen by the wayside.\n",
    "\n",
    "To paraphrase the authors, this text aims to \"have it all\" by developing a framework for doing just this, with a focus on formal semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Necessary background\n",
    "\n",
    "The book seems to be primarily aimed at theoretical linguists, rather than psycholinguists or cognitive scientists *per se*.\n",
    "\n",
    "On the theory side, the authors presuppose basic formal syntax/semantics, \n",
    "\n",
    "In later chapters, there will be a focus on Hans Kamp's *Discourse Representation Theory*, although we won't get there for a little while."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python\n",
    "\n",
    "The ACT-R architecture was implemented as `pyactr` the second author in python. This library is used throughout the book: https://github.com/jakdot/pyactr\n",
    "\n",
    "The *official* implementation of ACT-R is in common lisp: http://act-r.psy.cmu.edu/software/\n",
    "\n",
    "As far as I can see, it's not necessary to really know python in order to use `pyactr`. You can think of `pyactr` as a DSL for manipulating ACT-R models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Today (chapter 2)\n",
    "\n",
    "Chapter 2 introduces the ACT-R cognitive architecture and the `pyactr` implementation.\n",
    "\n",
    "The main example will be a super simple model of subject verb agreement. There will be some other non-linguistic examples too.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cognitive architectures\n",
    "\n",
    "ACT-R - which stands for **Adaptive Control of Thought-Rational** is a *cognitive architecture*\n",
    "\n",
    "A *cognitive architecture* \"...specifies the general structure of the human mind at a level of abstraction that is sufficient to capture how the mind achieves its goals.\"\n",
    "\n",
    "We want to be able to talk about mental processes a few steps above \"the bare metal\" (or brain, in this instance). ACT-R is a cognitive architecture with a relatively high level of abstraction, which has been used, e.g., to model equation solving and other higher level processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Kinds of models in cognitive science\n",
    "\n",
    "## Descriptive models\n",
    "\n",
    "Descriptive models aim to \"...replace the intricacies of a full data set with a simpler representation in terms of the model's parameters\".\n",
    "\n",
    "\n",
    "## Characterization models\n",
    "\n",
    "These identify and measure cognitive stages, but are neutral wrt the exact mechanics of those stages.\n",
    "\n",
    "B&D describe competence theories of syntax and semantics as *characterization* models.\n",
    "\n",
    "## Process models\n",
    "\n",
    "Process models describe all cognitive processes in detail and leave nothing within their scope unspecified.\n",
    "\n",
    "In other words, a process model is an (explicit) *performance* model. ACT-R is a process model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why do (theoretical) linguists need process models?\n",
    "\n",
    "Why aren't characterization (competence) models enough for the questions that linguists are interested?\n",
    "\n",
    "We can't always tell whether or not the best analysis of a given phenomenon is the remit of a a competence theory, a performance theory, or both.\n",
    "\n",
    "Often, performance is treated as a kind of wastebasket, without an explicit understanding of how competence theories feed into processing models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ACT-R\n",
    "\n",
    "The textbook only gives a cursory overview of the ACT-R cognitive architecture. Some important reference points:\n",
    "\n",
    "- The official website: http://act-r.psy.cmu.edu/\n",
    "- Anderson, J. R. (1990). *Cognitive Psychology and its Implications*. \n",
    "- Anderson, J. R. & Lebiere, C. (1998). *The atomic components of thought*.\n",
    "- Anderson, J. R., Bothell, D., Byrne, M. D., Douglass, S., Lebiere, C., & Qin, Y . (2004). An integrated theory of the mind. *Psychological Review* 111, (4). 1036-1060"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Applications of ACT-R in linguistics\n",
    "\n",
    "B&D describe it as \"the most popular cognitive architecture in linguistics\".\n",
    "\n",
    "Its predecessor ACT was used by Anderson (1976) to model facts about language and grammar, but abandoned soon after due to criticisms from Wexler (1978).\n",
    "\n",
    "More recently, Lewis and Vasishth (2005) implemented left-corner parsers in ACT-R. This will be a goal in the next chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Symbolic and sub-symbolic components\n",
    "\n",
    "ACT-R is a good fit for modeling linguistic phenomena because it is a *hybrid* architecture.\n",
    "\n",
    "This means that it combines both symbolic and sub-symbolic components.\n",
    "\n",
    "The symbolic components allow us to incorporate competence theories in a fiarly straightforward fashion.\n",
    "\n",
    "Subsymbolic components enable the resulting models to make detailed quantitative predictions for performance, that we can check against experimental data.\n",
    "\n",
    "If it meets this promise, then this model constitutes a linking theory, and that's exciting! N.b. in this chapter the authors only introduce the symbolic components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Knowledge in ACT-R\n",
    "\n",
    "There are two types of knowledge in ACT-R:\n",
    "\n",
    "- *Declarative knowledge*\n",
    "- *Prodedural knowledge*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Declarative knowledge\n",
    "\n",
    "At a high level of abstraction, declarative knowledge is our knowledge of *facts*.\n",
    "\n",
    "In philosophical terms, declarative knowledge corresponds to \"knowing what\" (as opposed to \"knowing how\").\n",
    "\n",
    "In the model, declarative knowledge is encoded in a mathematical construct called a *chunk*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Chunks\n",
    "\n",
    "Chunks are attribute-value lists, although in ACT-R, we call the attributes *slots*.\n",
    "\n",
    "If you're familiar with programming, you can think of chunks as records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A straightforward example\n",
    "\n",
    "We can model lexical knowledge in ACT-R via chunks. For example, we can model knowledge of the word *car* as a chunk of type WORD, with:\n",
    "\n",
    "- the value \"car\" for the slot FORM.\n",
    "- the value $[\\lambda x\\,.\\,\\mathsf{car}(x)]$ for the slot MEANING.\n",
    "- the value 'noun' for the slot CATEGORY.\n",
    "- the value 'sg' for the slot NUMBER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](img/word.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![The standard representation as an attribute-value matrix](img/av.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Procedural memory\n",
    "\n",
    "- In ACT-R procedural memory is modelled as a production - where a \"production\" is simply a conditional statement.\n",
    "- Productions describe actions that take place if a set of preconditions are satisfied.\n",
    "- We can think of productions as (precondition,action) pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A straightforward example\n",
    "\n",
    "We might want to model knowledge of number agreement in English via procedural memory.\n",
    "\n",
    "\"If the number slot of the subject NP in the sentence currently under construction has the value sg (precondition), then check that the number slot of the main verb also has the value sg (action).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As noted by B&D, technically we'd need another, seperate rule for plural agreement, but this seems to missing an omportant generalization.\n",
    "\n",
    "In ACT-R, we can have variables that scope within productions, i.e.\n",
    "\n",
    "\"If the number slot of the subject NP in the sentence currently under construction has the value `=x`, then check that the number slot of the main verb also has the value `=x`.\"\n",
    "\n",
    "In this way, ACT-R allows us to state generalizations directly as productions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Getting our hands dirty\n",
    "\n",
    "What you'll need:\n",
    "- A python environment with `pyactr` installed - and, optionally, `ipython` if you want an interactive environment like the one i'm using here.\n",
    "- You can find the code used to generate this notebook, which includes jupyter, ipython, and `pyactr` here: https://github.com/patrl/actr-notebook\n",
    "- A straightforward way of reproducing the environment i'm using here is to take the `poetry.lock` file from my repository, copy it to a directory, and do `poetry install` (you'll need the python dependency manager `poetry` (https://python-poetry.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The basics: declaring chunks\n",
    "\n",
    "To use `pyactr` we first need to import the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pyactr as actr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Chunks are *typed* - before introducing a chunk, we need to specify a chunk type and the slots it contains. This is just good housekeeping.\n",
    "\n",
    "Let's first declare a chunk type to model lexical knowledge.\n",
    "\n",
    "The `chunktype` function creates a type `word` with some slots, seperated by commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "actr.chunktype(\"word\", \"form, meaning, category, number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now that we've declared a chunk type, we can create chunks of that type.\n",
    "\n",
    "Note that the function `makechunk` only has two obligatory arguments:\n",
    " - `typename`\n",
    " - `nameofchunk`\n",
    " \n",
    " Unspecified slots are left empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word(category= noun, form= car, meaning= [[car]], number= sg)\n"
     ]
    }
   ],
   "source": [
    "carLexeme = actr.makechunk(nameofchunk=\"car1\",\n",
    "                          typename=\"word\",\n",
    "                          form=\"car\",\n",
    "                          meaning=\"[[car]]\",\n",
    "                          category=\"noun\",\n",
    "                          number=\"sg\")\n",
    "\n",
    "print(carLexeme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "N.b. python prints the slots in alphabetical order. This is because chunks are *unordered* sets of slot-value pairs, and python defaults to alphabetical order when printing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# An aside on types\n",
    "\n",
    "Specifying chunk types is really just good housekeeping, but in actual fact optional.\n",
    "\n",
    "In ACT-R, type names have no theoretical significance - chunk types are are identified by the sloots they contain. This means that the following chunks are *identical*.\n",
    "\n",
    "- `word(category= noun, form= car, meaning= [[car]], number= sg)`\n",
    "- `lexeme(category= noun, form= car, meaning= [[car]], number= sg)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extending chunks\n",
    "\n",
    "Chunks can be extended with new slots not originally present in the chunk type declaration.\n",
    "\n",
    "`carLexeme2` is like `carLexeme`, but extended with a new slot `synfunction`.\n",
    "\n",
    "The evaluator will output a warning, but everything will proceed just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "carLexeme2 = actr.makechunk(nameofchunk=\"car1\",\n",
    "                            typename=\"word\",\n",
    "                          form=\"car\",\n",
    "                          meaning=\"[[car]]\",\n",
    "                          category=\"noun\",\n",
    "                          number=\"sg\",\n",
    "                           synfunction=\"subj\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# An alternative method for specifying chunks\n",
    "\n",
    "The `chunkstring` function is an alternative method for declaring a new chunk:\n",
    "\n",
    "(n.b. triple quotation in python indicates that a string can appear on more than one line.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "carLexeme3 = actr.chunkstring(string=\"\"\"\n",
    "    isa word\n",
    "    form car\n",
    "    meaning '[[car]]'\n",
    "    category noun\n",
    "    number sg\n",
    "    synfunction subj\n",
    "\"\"\")\n",
    "\n",
    "print(carLexeme3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Equality and implication\n",
    "\n",
    "Treating chunks as attribute value sets induces natural notions of equality and implication. The standard python comparison operators are overloaded to reflect this.\n",
    "\n",
    "N.b. the chunk type is completely ignored for the purpose of these comparisons; the chunk type is just syntactic sugar for human modellers, it has no status in the theory of ACT-R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(carLexeme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(carLexeme2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(carLexeme3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "carLexeme2 == carLexeme3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "carLexeme == carLexeme2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "carLexeme < carLexeme2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modules and buffers\n",
    "\n",
    "Now we can declare chunks, but what can we do with them?\n",
    "\n",
    "Chunks don't live in a vacuum, but rather are part of an ACT-R mind (an instantiation of the ACT-R architecture).\n",
    "\n",
    "Minds are made up of *modules* and *buffers*.\n",
    "\n",
    "Modules each serve a different mental function, but cannot be accessed or updated directly. Rather I/O operations on modules are via an intermediary - the associated buffer.\n",
    "\n",
    "Each module comes equipped with one such buffer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Serial vs. parallel components\n",
    "\n",
    "A central feature of ACT-R is that each buffer can only carry a single chunk at any given time.\n",
    "\n",
    "For example, the declarative memory module is associated with a buffer - the *retrieval* buffer.\n",
    "\n",
    "Internally, the module supports massively parallel processes; all chunks can be simultaneously checked against a cue.\n",
    "\n",
    "Externally, the module can only be accessed by serially placing one cue at a time in its associated retrieval buffer.\n",
    "\n",
    "In ACT-R actual cognitive behavior is modelled by combining serial and parallel components in specific ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The procedural memory module\n",
    "\n",
    "The flow of information in the mind is driven by productions, which dictate transactions between modules and associated buffers. \n",
    "\n",
    "Remember that productions are stored in procedural memory, itself a module. In this chapter, we primarily look at the interaction between declarative and procedural memory.\n",
    "\n",
    "Since cognition is driven by productions, the procedural memory module is asumed to be always present in any given mind; it doesn't have to be explicitly declared.\n",
    "\n",
    "The buffer associated with this module is called the **goal** buffer, and it plays a hugely important role in ACT-R models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Building a mind\n",
    "\n",
    "We're going to build an extremely simple mind that can do subject agreement.\n",
    "\n",
    "First, let's build a container for a mind (a model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "agreement = actr.ACTRModel ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For convenience, any model comes with a declarative memory module with an empty retrieval buffer. Modules are attributes of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "These modules and buffers start out empty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreement.decmem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreement.goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreement.retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's declare a shorter alias for the declarative memory module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dm = agreement.decmem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adding chunks to declarative memory\n",
    "\n",
    "We can invoke the `add` method associated with the declarative memory module in order to add chunks to declarative memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "carLexeme = actr.makechunk(\n",
    "    nameofchunk=\"car\",\n",
    "    typename=\"word\",\n",
    "    meaning=\"[[car]]\",\n",
    "    category=\"noun\",\n",
    "    number=\"sg\",\n",
    "    synfunction=\"subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{word(category= noun, form= car, meaning= [[car]], number= sg, synfunction= subj): array([0.]), word(category= noun, form= , meaning= [[car]], number= sg, synfunction= subject): array([0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "dm.add(carLexeme)\n",
    "print(dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that when we inspect `dm`, we see the chunk we just added, alongside the chunk encoding time. Since we haven't run the model yet, this time is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modeling subject-verb agreement\n",
    "\n",
    "In order to model subject-verb agreement, we're going to be making some simplifying assumptions. We won't say anything about how parsing works, just assume that declarative memory already contains the subject  of the clause, and the current verb is present in the goal buffer.\n",
    "\n",
    "We're going to need three productions in procedural memory:\n",
    "\n",
    "1. if the goal has a verb chunk, and the current task is to agree, then retrieve the subject.\n",
    "2. If the number of the subject is `=x`, then the number of the verb in the goal should also be `=x`.\n",
    "3. If the verb is assigned a number, the task is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Writing productions: noun retrieval\n",
    "\n",
    "Productions are created by the method `productionstring`.\n",
    "\n",
    "The `==>` acts as a seperator between the preconditions and the actions.\n",
    "\n",
    "Preconditions are specified for two buffers.\n",
    "- `=g>` indicates the target buffer (`g`: the *goal* buffer), and the type of precondition this buffer has to satisfy (`=`: subsumption; this is highly confusing!). So, the chunk currently stored in the goal buffer must be subsumed by the chunk characterised on the following lines. .\n",
    "- `?retrieval>` checks whether the retrieval buffer is in a certain state. The `?` symbol indicates that we're interested in the state of the buffer, not the chunk inside of it. The buffer must be empty for this precondition to be satisfied.\n",
    "\n",
    "In general we can use `?` to submit a variety of queries regarding the state of buffers.\n",
    "\n",
    "```\n",
    "agreement.productionstring(name=\"retrieve\", string=\"\"\"\n",
    "    =g>\n",
    "    isa goal_lexeme\n",
    "    category verb\n",
    "    task agree\n",
    "    ?retrieval>\n",
    "    buffer empty\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If the preconditions are both met, two actions are triggered.\n",
    "-  The current task of the `goal_lexeme` chunk is changed to `trigger_agreement`. This isn' reflected in the book, but it looks like this is really the only thing that needs to be specified.\n",
    "- The second action is to add a new chunk to the retrieval buffer, this is what the `+` symbol indicates. What gets added to the retrieval buffer is a noun that is the subject of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'=g': goal_lexeme(category= verb, task= agree), '?retrieval': {'buffer': 'empty'}}\n",
       "==>\n",
       "{'=g': goal_lexeme(category= verb, task= trigger_agreement), '+retrieval': word(category= noun, form= , meaning= , number= , synfunction= subject)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actr.chunktype(\"goal_lexeme\",\"category, task\")\n",
    "\n",
    "agreement.productionstring(name=\"retrieve\", string=\"\"\"\n",
    "    =g>\n",
    "    isa goal_lexeme\n",
    "    category verb\n",
    "    task agree\n",
    "    ?retrieval>\n",
    "    buffer empty\n",
    "    ==>\n",
    "    =g>\n",
    "    isa goal_lexeme\n",
    "    task trigger_agreement\n",
    "    category verb\n",
    "    +retrieval>\n",
    "    isa word\n",
    "    category noun\n",
    "    synfunction subject\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Triggering agreement\n",
    "\n",
    "We now define a second production rule to actually perform the agreement. This comes with two preconditions that check that we are in the correct state:\n",
    "- The chunk in the goal buffer is subsumed by the chunk described here.\n",
    "- The chunk in the retrieval buffer is subsumed by the chunk described here.\n",
    "\n",
    "```\n",
    "agreement.productionstring(name=\"agree\", string=\"\"\"\n",
    "    =g>\n",
    "    isa goal_lexeme\n",
    "    task trigger_agreement\n",
    "    category verb\n",
    "    =retrieval>\n",
    "    isa word\n",
    "    category noun\n",
    "    synfunction subject\n",
    "    number =x\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we're in the correct state, the action is triggered:\n",
    "- the chunk in the goal buffer is *updated* such that a new number specification is added, which matches the one on the subject noun we retrieved from declarative memory.\n",
    "- The task is marked as done.\n",
    "\n",
    "```\n",
    "   ==>\n",
    "    =g>\n",
    "    isa goal_lexeme\n",
    "    category verb\n",
    "    number =x\n",
    "    task done\n",
    "    \"\"\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The full production:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'=g': goal_lexeme(category= verb, task= trigger_agreement), '=retrieval': word(category= noun, form= , meaning= , number= =x, synfunction= subject)}\n",
       "==>\n",
       "{'=g': goal_lexeme(category= verb, number= =x, task= done)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreement.productionstring(name=\"agree\", string=\"\"\"\n",
    "    =g>\n",
    "    isa goal_lexeme\n",
    "    task trigger_agreement\n",
    "    category verb\n",
    "    =retrieval>\n",
    "    isa word\n",
    "    category noun\n",
    "    synfunction subject\n",
    "    number =x\n",
    "    ==>\n",
    "    =g>\n",
    "    isa goal_lexeme\n",
    "    category verb\n",
    "    number =x\n",
    "    task done\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clean-up\n",
    "\n",
    "The final production rule mops things up, flushing the goal buffer.\n",
    "\n",
    "`~g>` discards the chunk in the goal buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'=g': goal_lexeme(category= , number= , task= done)}\n",
       "==>\n",
       "{'~g': None}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreement.productionstring(name=\"done\", string=\"\"\"\n",
    "=g>\n",
    "isa goal_lexeme\n",
    "task done\n",
    "==>\n",
    "~g>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](img/precon.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](img/action.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Running the model\n",
    "\n",
    "To get things off the ground, we need to add a goal lexeme to the goal buffer.\n",
    "\n",
    "Since according to ACT-R, higher cognition is goal driven, nothing will happen in the absence of a goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{goal_lexeme(category= verb, number= , task= agree)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actr.chunktype(\"goal_lexeme\", \"task, category, number\")\n",
    "\n",
    "agreement.goal.add(actr.chunkstring(string=\"\"\"\n",
    "    isa goal_lexeme\n",
    "    task agree\n",
    "    category verb\"\"\"))\n",
    "\n",
    "agreement.goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can now run the model by invoking the `simulation` method. The output of the `run()` command is the temporal trace of our model simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "agreement_sim = agreement.simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'PROCEDURAL', 'CONFLICT RESOLUTION')\n",
      "(0, 'PROCEDURAL', 'RULE SELECTED: retrieve')\n",
      "(0.05, 'PROCEDURAL', 'RULE FIRED: retrieve')\n",
      "(0.05, 'g', 'MODIFIED')\n",
      "(0.05, 'retrieval', 'START RETRIEVAL')\n",
      "(0.05, 'PROCEDURAL', 'CONFLICT RESOLUTION')\n",
      "(0.05, 'PROCEDURAL', 'NO RULE FOUND')\n",
      "(0.1, 'retrieval', 'CLEARED')\n",
      "(0.1, 'retrieval', 'RETRIEVED: word(category= noun, form= , meaning= [[car]], number= sg, synfunction= subject)')\n",
      "(0.1, 'PROCEDURAL', 'CONFLICT RESOLUTION')\n",
      "(0.1, 'PROCEDURAL', 'RULE SELECTED: agree')\n",
      "(0.15, 'PROCEDURAL', 'RULE FIRED: agree')\n",
      "(0.15, 'g', 'MODIFIED')\n",
      "(0.15, 'PROCEDURAL', 'CONFLICT RESOLUTION')\n",
      "(0.15, 'PROCEDURAL', 'RULE SELECTED: done')\n",
      "(0.2, 'PROCEDURAL', 'RULE FIRED: done')\n",
      "(0.2, 'g', 'CLEARED')\n",
      "(0.2, 'PROCEDURAL', 'CONFLICT RESOLUTION')\n",
      "(0.2, 'PROCEDURAL', 'NO RULE FOUND')\n"
     ]
    }
   ],
   "source": [
    "agreement_sim.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Observe that when we run a simulation, every cognitive step takes 50ms. This is the ACT-R default for an elementary cognitive step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The counting model\n",
    "\n",
    "## The task\n",
    "\n",
    "- Given an initial number $n$, and a final number $m$, increment $n$ until $m$ is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Chunks\n",
    "\n",
    "We're going to need two chunk types to model the kind of information stored:\n",
    "\n",
    "- `countOrder` stores the initial number and the end point, as a pair.\n",
    "- `countFrom` stores the current state of the counting process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "counting = actr.ACTRModel()\n",
    "actr.chunktype(\"countOrder\", (\"first\",\"second\"))\n",
    "actr.chunktype(\"countFrom\", (\"start\", \"end\", \"count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Counting from 2 to 4\n",
    "\n",
    "We can simulate counting from 2 to 4 by encoding these parameters in the goal buffer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "counting.goal.add(actr.chunkstring(string=\"\"\"\n",
    "isa countFrom\n",
    "start 2\n",
    "end 4\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "next we store counting knowledge in declarative memory. In the example given, we have to store information about what is the successor of what.\n",
    "\n",
    "...this is a bit tedious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dm = counting.decmem\n",
    "\n",
    "dm.add(actr.chunkstring(string=\"\"\"\n",
    "isa countOrder\n",
    "first 1\n",
    "second 2\n",
    "\"\"\"))\n",
    "\n",
    "dm.add(actr.chunkstring(string=\"\"\"\n",
    "isa countOrder\n",
    "first 2\n",
    "second 3\n",
    "\"\"\"))\n",
    "\n",
    "dm.add(actr.chunkstring(string=\"\"\"\n",
    "isa countOrder\n",
    "first 3\n",
    "second 4\n",
    "\"\"\"))\n",
    "\n",
    "dm.add(actr.chunkstring(string=\"\"\"\n",
    "isa countOrder\n",
    "first 4\n",
    "second 5\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, the model has three rules:\n",
    "\n",
    "- `start`\n",
    "- `incremement`\n",
    "- `stop`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `start`\n",
    "\n",
    "### Preconditions\n",
    "\n",
    "- The goal buffer has a chunk that has no value for the `count` slot.\n",
    "- The slot `start` has the value `=x` (this is trivially satisfied).\n",
    "\n",
    "### Actions\n",
    "\n",
    "- In tthe goal buffer, the value of `count` is assigned the value of the variable `=x`.\n",
    "- We place a retrieval request for a declarative memory chunk that has the value `=x` in the slot first (the successor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'=g': countFrom(count= None, end= , start= =x)}\n",
       "==>\n",
       "{'=g': countFrom(count= =x, end= , start= ), '+retrieval': countOrder(first= =x, second= )}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counting.productionstring(name=\"start\", string=\"\"\"\n",
    "=g>\n",
    "isa countFrom\n",
    "start =x\n",
    "count None\n",
    "==>\n",
    "=g>\n",
    "isa countFrom\n",
    "count =x\n",
    "+retrieval>\n",
    "isa countOrder\n",
    "first =x\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `increment`\n",
    "\n",
    "### Preconditions\n",
    "\n",
    "- The value of `count` in the goal buffer doesn't match the final `end` value (`~` is negation).\n",
    "- The retrieval buffer carries a chunk whose `first` value matches the `count` value in the goal buffer.\n",
    "\n",
    "### Actions\n",
    "- Update the current `count` value with the value of its successor.\n",
    "- Place a retrieval request for the next increment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'=g': countFrom(count= =x, end= ~=x, start= ), '=retrieval': countOrder(first= =x, second= =y)}\n",
       "==>\n",
       "{'=g': countFrom(count= =y, end= , start= ), '+retrieval': countOrder(first= =y, second= )}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counting.productionstring(name=\"increment\", string=\"\"\"\n",
    "    =g>\n",
    "    isa     countFrom\n",
    "    count   =x\n",
    "    end     ~=x\n",
    "    =retrieval>\n",
    "    isa     countOrder\n",
    "    first   =x\n",
    "    second  =y\n",
    "    ==>\n",
    "    =g>\n",
    "    isa     countFrom\n",
    "    count   =y\n",
    "    +retrieval>\n",
    "    isa     countOrder\n",
    "    first   =y\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `stop`\n",
    "\n",
    "If the current count matches the final number, clear the goal buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'=g': countFrom(count= =x, end= =x, start= )}\n",
       "==>\n",
       "{'~g': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counting.productionstring(name=\"stop\", string=\"\"\"\n",
    "    =g>\n",
    "    isa     countFrom\n",
    "    count   =x\n",
    "    end     =x\n",
    "    ==>\n",
    "    ~g>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'PROCEDURAL', 'CONFLICT RESOLUTION')\n",
      "(0, 'PROCEDURAL', 'RULE SELECTED: start')\n",
      "(0.05, 'PROCEDURAL', 'RULE FIRED: start')\n",
      "(0.05, 'g', 'MODIFIED')\n",
      "(0.05, 'retrieval', 'START RETRIEVAL')\n",
      "(0.05, 'PROCEDURAL', 'CONFLICT RESOLUTION')\n",
      "(0.05, 'PROCEDURAL', 'NO RULE FOUND')\n",
      "(0.1, 'retrieval', 'CLEARED')\n",
      "(0.1, 'retrieval', 'RETRIEVED: countOrder(first= 2, second= 3)')\n",
      "(0.1, 'PROCEDURAL', 'CONFLICT RESOLUTION')\n",
      "(0.1, 'PROCEDURAL', 'RULE SELECTED: increment')\n",
      "(0.15, 'PROCEDURAL', 'RULE FIRED: increment')\n",
      "(0.15, 'g', 'MODIFIED')\n",
      "(0.15, 'retrieval', 'START RETRIEVAL')\n",
      "(0.15, 'PROCEDURAL', 'CONFLICT RESOLUTION')\n",
      "(0.15, 'PROCEDURAL', 'NO RULE FOUND')\n",
      "(0.2, 'retrieval', 'CLEARED')\n",
      "(0.2, 'retrieval', 'RETRIEVED: countOrder(first= 3, second= 4)')\n",
      "(0.2, 'PROCEDURAL', 'CONFLICT RESOLUTION')\n",
      "(0.2, 'PROCEDURAL', 'RULE SELECTED: increment')\n",
      "(0.25, 'PROCEDURAL', 'RULE FIRED: increment')\n",
      "(0.25, 'g', 'MODIFIED')\n",
      "(0.25, 'retrieval', 'START RETRIEVAL')\n",
      "(0.25, 'PROCEDURAL', 'CONFLICT RESOLUTION')\n",
      "(0.25, 'PROCEDURAL', 'RULE SELECTED: stop')\n",
      "(0.3, 'retrieval', 'CLEARED')\n",
      "(0.3, 'PROCEDURAL', 'RULE FIRED: stop')\n",
      "(0.3, 'retrieval', 'RETRIEVED: countOrder(first= 4, second= 5)')\n",
      "(0.3, 'g', 'CLEARED')\n",
      "(0.3, 'PROCEDURAL', 'CONFLICT RESOLUTION')\n",
      "(0.3, 'PROCEDURAL', 'NO RULE FOUND')\n"
     ]
    }
   ],
   "source": [
    "counting_sim = counting.simulation()\n",
    "counting_sim.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regular grammars in ACT-R\n",
    "\n",
    "A (right-)regular grammar has rules of the following form:\n",
    "\n",
    "- $X \\rightarrow a\\,Y$\n",
    "- $X \\rightarrow a$ \n",
    "- $X \\rightarrow \\epsilon$\n",
    "\n",
    "Lower case variables are terminals, and upper-case variables are non-terminals.\n",
    "\n",
    "Right-regular gramars aren't expressive enough for natural languages, but make a good illustrative example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here we implement a right-regular grammar in ACT-R that generates NP constituents consisting of indefinitely long strings of nouns.\n",
    "\n",
    "$$\\mathrm{NP} \\rightarrow \\mathrm{N}\\,\\mathrm{NP}$$\n",
    "\n",
    "We only need one chunk type - `goal_chunk` - which encodes the single rule in our grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "regular_grammar = actr.ACTRModel()\n",
    "\n",
    "actr.chunktype(\"goal_chunk\", \"mother daughter1 daughter2 state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We initialize the goal buffer to an NP `mother` node. The value of `state` will be `rule`, which signals that the rewrite rule should be triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "regular_grammar.goal.add(actr.chunkstring(string=\"\"\"\n",
    "isa goal_chunk\n",
    "mother NP\n",
    "state rule\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We only need three prodecures:\n",
    "- One which rewrites an NP mother node as the daughters N NP.\n",
    "- One that prints the first daughter.\n",
    "- One that sets the second daughter as the current node, so that the rule can apply again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The rewrite rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'=g': goal_chunk(daughter1= None, daughter2= None, mother= NP, state= rule)}\n",
       "==>\n",
       "{'=g': goal_chunk(daughter1= N, daughter2= NP, mother= , state= show)}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_grammar.productionstring(name=\"NP ==> N NP\", string=\"\"\"\n",
    "    =g>\n",
    "    isa         goal_chunk\n",
    "    mother      NP\n",
    "    daughter1   None\n",
    "    daughter2   None\n",
    "    state       rule\n",
    "    ==>\n",
    "    =g>\n",
    "    isa         goal_chunk\n",
    "    daughter1   N\n",
    "    daughter2   NP\n",
    "    state       show\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The printing rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'=g': goal_chunk(daughter1= , daughter2= , mother= , state= show)}\n",
       "==>\n",
       "{'!g': ([(['show', 'daughter1'], {})], {}), '=g': goal_chunk(daughter1= , daughter2= , mother= , state= rule)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_grammar.productionstring(name=\"print N\", string=\"\"\"\n",
    "    =g>\n",
    "    isa         goal_chunk\n",
    "    state       show\n",
    "    ==>\n",
    "    !g>\n",
    "    show        daughter1\n",
    "    =g>\n",
    "    isa         goal_chunk\n",
    "    state       rule\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# A rule to set the daughter as the current node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'=g': goal_chunk(daughter1= , daughter2= =x~None, mother= , state= rule)}\n",
       "==>\n",
       "{'=g': goal_chunk(daughter1= None, daughter2= None, mother= =x, state= )}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_grammar.productionstring(name=\"get new mother\", string=\"\"\"\n",
    "    =g>\n",
    "    isa         goal_chunk\n",
    "    daughter2   =x\n",
    "    daughter2   ~None\n",
    "    state       rule\n",
    "    ==>\n",
    "    =g>\n",
    "    isa         goal_chunk\n",
    "    mother      =x\n",
    "    daughter1   None\n",
    "    daughter2   None\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can now run the simulation for different oamounts  of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daughter1 N\n",
      "daughter1 N\n",
      "daughter1 N\n"
     ]
    }
   ],
   "source": [
    "regular_grammar_sim = regular_grammar.simulation(trace=False)\n",
    "\n",
    "regular_grammar_sim.run(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daughter1 N\n",
      "daughter1 N\n",
      "daughter1 N\n",
      "daughter1 N\n",
      "daughter1 N\n",
      "daughter1 N\n",
      "daughter1 N\n",
      "daughter1 N\n",
      "daughter1 N\n",
      "daughter1 N\n"
     ]
    }
   ],
   "source": [
    "regular_grammar_sim.run(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can turn the trace back"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
